<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Machine Learning Resources | Piyush Tiwary</title> <meta name="author" content="Piyush Tiwary"> <meta name="description" content="list of resources for ml"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://backpropagator.github.io/blog/2019/ml/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-DP8LD8Z4LH"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-DP8LD8Z4LH");</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Piyush </span>Tiwary</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Machine Learning Resources</h1> <p class="post-meta">July 13, 2019</p> <p class="post-tags"> <a href="/blog/2019"> <i class="fas fa-calendar fa-sm"></i> 2019 </a>   ·   <a href="/blog/tag/resource"> <i class="fas fa-hashtag fa-sm"></i> resource</a>     ·   <a href="/blog/category/resource"> <i class="fas fa-tag fa-sm"></i> resource</a>   </p> </header> <article class="post-content"> <h2 id="resources">Resources</h2> <h3 id="table-of-contents">Table of Contents</h3> <ul> <li> <p><strong><a href="#personal-favourites">Personal Favourites</a></strong></p> </li> <li> <p><strong><a href="#blogs">Some Nice Blogs</a></strong></p> </li> <li> <p><strong><a href="#free-online-books">Free Online Books</a></strong></p> </li> <li> <p><strong><a href="#courses">Courses</a></strong></p> </li> <li> <p><strong><a href="#videos-and-lectures">Videos and Lectures</a></strong></p> </li> <li> <p><strong><a href="#tutorials">Tutorials</a></strong></p> </li> <li> <p><strong><a href="#researchers">Researchers</a></strong></p> </li> <li> <p><strong><a href="#websites">WebSites</a></strong></p> </li> <li> <p><strong><a href="#datasets">Datasets</a></strong></p> </li> <li> <p><strong><a href="#Conferences">Conferences</a></strong></p> </li> <li> <p><strong><a href="#frameworks">Frameworks</a></strong></p> </li> <li> <p><strong><a href="#miscellaneous">Miscellaneous</a></strong></p> </li> <li> <p><strong><a href="#contributing">Contributing</a></strong></p> </li> </ul> <h3 id="personal-favourites">Personal Favourites</h3> <ol> <li>Probabilistic Machine Learning - <a href="https://probml.github.io/pml-book/book0.html" rel="external nofollow noopener" target="_blank">Book 0</a>, <a href="https://probml.github.io/pml-book/book1.html" rel="external nofollow noopener" target="_blank">Book 1</a>, <a href="https://probml.github.io/pml-book/book2.html" rel="external nofollow noopener" target="_blank">Book 2</a> by Kevin Murphy (really nice books)</li> <li> <a href="http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf" rel="external nofollow noopener" target="_blank">Pattern Recognition And Machine Learning</a> by Christopher M. Bishop.</li> <li> <a href="http://books.ranvier.ir/download.php?file=Cognitive_Model%20Thad%20A.%20Polk%20Colleen%20M.Seifert.pdf" rel="external nofollow noopener" target="_blank">Cognitive Modeling</a> by Thad A. Polk and Colleen M. Seifert.</li> <li> <a href="https://www.youtube.com/watch?v=BCiZc0n6COY&amp;list=PLruBu5BI5n4aFpG32iMbdWoRVAA-Vcso6" rel="external nofollow noopener" target="_blank">The Information Theory, Pattern Recognition, and Neural Networks Lecture Series</a> by David MackKay (gives essence of Bayesian Inference and how it connects with Neural Networks).</li> <li> <a href="http://www.inference.org.uk/itprnn/book.pdf" rel="external nofollow noopener" target="_blank">Information Theory, Inference, and Learning Algorithms</a> by David J.C. MacKay (this is the course book for above mentioned lecture series, Do Read!).</li> <li> <a href="https://colah.github.io/" rel="external nofollow noopener" target="_blank">Christopher Olah’s Blog</a> - Nicely explained concepts and many exciting things!</li> </ol> <h3 id="some-nice-blogs">Some Nice Blogs</h3> <ol> <li> <a href="http://karpathy.github.io/" rel="external nofollow noopener" target="_blank">Andrej Karpathy blog</a> some really nice blogs by Andrej Karpathy</li> <li> <a href="https://colah.github.io/" rel="external nofollow noopener" target="_blank">Christopher Olah’s Blog</a> - Nicely explained concepts One should have a look if interested in some Insights to Neural Networks.</li> <li> <a href="http://obsessionwithregression.blogspot.com/" rel="external nofollow noopener" target="_blank">Obsession with Regression</a> by Emma Pierson.</li> <li><a href="https://juliagalef.com/" rel="external nofollow noopener" target="_blank">Julia Galef’s Blog</a></li> <li><a href="https://yoshuabengio.org/" rel="external nofollow noopener" target="_blank">Yoshua Bengio’s Blogs</a></li> <li> <a href="https://aiweirdness.com/" rel="external nofollow noopener" target="_blank">AIWierdness</a> some “Wierd” things here.</li> <li> <a href="https://otoro.net/" rel="external nofollow noopener" target="_blank">Otoro.net</a> some really simple things which use DL and seems very cool.</li> <li> <a href="https://francisbach.com/" rel="external nofollow noopener" target="_blank">Machine Learning Research Blog</a> by Francis Bach (useful for Researchers to get insight).</li> <li><a href="https://ai.googleblog.com/" rel="external nofollow noopener" target="_blank">Google AI Blog</a></li> <li><a href="https://openai.com/blog/" rel="external nofollow noopener" target="_blank">OpenAI Blog</a></li> <li><a href="https://deepmind.com/blog" rel="external nofollow noopener" target="_blank">DeepMind Blog</a></li> <li><a href="https://bair.berkeley.edu/blog/" rel="external nofollow noopener" target="_blank">Berkeley Artificial Intelligence Research (BAIR)</a></li> <li><a href="http://news.mit.edu/topic/machine-learning" rel="external nofollow noopener" target="_blank">MIT News</a></li> <li> <a href="https://www.deeplearning.ai/thebatch/" rel="external nofollow noopener" target="_blank">The Batch</a> deeplearning.ai’s weekly newsletter.</li> <li><a href="https://www.kdnuggets.com/tag/machine-learning" rel="external nofollow noopener" target="_blank">KDnuggets</a></li> </ol> <h3 id="free-online-books">Free Online Books</h3> <ol> <li> <a href="http://neuralnetworksanddeeplearning.com/" rel="external nofollow noopener" target="_blank">Neural Networks and Deep Learning</a> by Michael Nielsen (Dec 2014)</li> <li> <a href="http://research.microsoft.com/pubs/209355/DeepLearning-NowPublishing-Vol7-SIG-039.pdf" rel="external nofollow noopener" target="_blank">Deep Learning</a> by Microsoft Research (2013)</li> <li> <a href="http://deeplearning.net/tutorial/deeplearning.pdf" rel="external nofollow noopener" target="_blank">Deep Learning Tutorial</a> by LISA lab, University of Montreal (Jan 6 2015)</li> <li> <a href="https://github.com/karpathy/neuraltalk" rel="external nofollow noopener" target="_blank">neuraltalk</a> by Andrej Karpathy : numpy-based RNN/LSTM implementation</li> <li><a href="https://svn-d1.mpi-inf.mpg.de/AG1/MultiCoreLab/papers/ebook-fuzzy-mitchell-99.pdf" rel="external nofollow noopener" target="_blank">An introduction to genetic algorithms</a></li> <li><a href="http://aima.cs.berkeley.edu/" rel="external nofollow noopener" target="_blank">Artificial Intelligence: A Modern Approach</a></li> <li><a href="http://arxiv.org/pdf/1404.7828v4.pdf" rel="external nofollow noopener" target="_blank">Deep Learning in Neural Networks: An Overview</a></li> <li><a href="https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/" rel="external nofollow noopener" target="_blank">Artificial intelligence and machine learning: Topic wise explanation</a></li> <li> <a href="https://doc.lagout.org/science/Artificial%20Intelligence/Machine%20learning/Machine%20Learning_%20A%20Probabilistic%20Perspective%20%5BMurphy%202012-08-24%5D.pdf" rel="external nofollow noopener" target="_blank">Machine Learning - A Probabilistic Perspective</a> by Kevin Murphy.</li> <li> <a href="http://books.ranvier.ir/download.php?file=Cognitive_Model%20Thad%20A.%20Polk%20Colleen%20M.Seifert.pdf" rel="external nofollow noopener" target="_blank">Cognitive Modeling</a> by Thad A. Polk and Colleen M. Seifert.</li> </ol> <h3 id="courses">Courses</h3> <ol> <li> <a href="https://class.coursera.org/ml-005" rel="external nofollow noopener" target="_blank">Machine Learning - Stanford</a> by Andrew Ng in Coursera (2010-2014)</li> <li> <a href="http://work.caltech.edu/lectures.html" rel="external nofollow noopener" target="_blank">Machine Learning - Caltech</a> by Yaser Abu-Mostafa (2012-2014)</li> <li> <a href="http://www.cs.cmu.edu/~tom/10701_sp11/lectures.shtml" rel="external nofollow noopener" target="_blank">Machine Learning - Carnegie Mellon</a> by Tom Mitchell (Spring 2011)</li> <li> <a href="https://class.coursera.org/neuralnets-2012-001" rel="external nofollow noopener" target="_blank">Neural Networks for Machine Learning</a> by Geoffrey Hinton in Coursera (2012)</li> <li> <a href="https://www.youtube.com/playlist?list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH" rel="external nofollow noopener" target="_blank">Neural networks class</a> by Hugo Larochelle from Université de Sherbrooke (2013)</li> <li> <a href="http://cilvr.cs.nyu.edu/doku.php?id=deeplearning:slides:start" rel="external nofollow noopener" target="_blank">Deep Learning Course</a> by CILVR lab @ NYU (2014)</li> <li> <a href="https://courses.edx.org/courses/BerkeleyX/CS188x_1/1T2013/courseware/" rel="external nofollow noopener" target="_blank">A.I - Berkeley</a> by Dan Klein and Pieter Abbeel (2013)</li> <li> <a href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/lecture-videos/" rel="external nofollow noopener" target="_blank">A.I - MIT</a> by Patrick Henry Winston (2010)</li> <li> <a href="http://web.mit.edu/course/other/i2course/www/vision_and_learning_fall_2013.html" rel="external nofollow noopener" target="_blank">Vision and learning - computers and brains</a> by Shimon Ullman, Tomaso Poggio, Ethan Meyers @ MIT (2013)</li> <li> <a href="http://vision.stanford.edu/teaching/cs231n/syllabus.html" rel="external nofollow noopener" target="_blank">Convolutional Neural Networks for Visual Recognition - Stanford</a> by Fei-Fei Li, Andrej Karpathy (2017)</li> <li><a href="http://cs224d.stanford.edu/" rel="external nofollow noopener" target="_blank">Deep Learning for Natural Language Processing - Stanford</a></li> <li><a href="http://info.usherbrooke.ca/hlarochelle/neural_networks/content.html" rel="external nofollow noopener" target="_blank">Neural Networks - usherbrooke</a></li> <li> <a href="https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/" rel="external nofollow noopener" target="_blank">Machine Learning - Oxford</a> (2014-2015)</li> <li> <a href="https://developer.nvidia.com/deep-learning-courses" rel="external nofollow noopener" target="_blank">Deep Learning - Nvidia</a> (2015)</li> <li> <a href="https://www.youtube.com/playlist?list=PLHyI3Fbmv0SdzMHAy0aN59oYnLy5vyyTA" rel="external nofollow noopener" target="_blank">Graduate Summer School: Deep Learning, Feature Learning</a> by Geoffrey Hinton, Yoshua Bengio, Yann LeCun, Andrew Ng, Nando de Freitas and several others @ IPAM, UCLA (2012)</li> <li> <a href="https://www.udacity.com/course/deep-learning--ud730" rel="external nofollow noopener" target="_blank">Deep Learning - Udacity/Google</a> by Vincent Vanhoucke and Arpan Chakraborty (2016)</li> <li> <a href="https://www.youtube.com/playlist?list=PLehuLRPyt1Hyi78UOkMPWCGRxGcA9NVOE" rel="external nofollow noopener" target="_blank">Deep Learning - UWaterloo</a> by Prof. Ali Ghodsi at University of Waterloo (2015)</li> <li> <a href="https://www.youtube.com/watch?v=azaLcvuql_g&amp;list=PLjbUi5mgii6BWEUZf7He6nowWvGne_Y8r" rel="external nofollow noopener" target="_blank">Statistical Machine Learning - CMU</a> by Prof. Larry Wasserman</li> <li> <a href="https://www.college-de-france.fr/site/en-yann-lecun/course-2015-2016.htm" rel="external nofollow noopener" target="_blank">Deep Learning Course</a> by Yann LeCun (2016)</li> <li><a href="https://www.youtube.com/playlist?list=PLkFD6_40KJIxopmdJF_CLNqG3QuDFHQUm" rel="external nofollow noopener" target="_blank">Designing, Visualizing and Understanding Deep Neural Networks-UC Berkeley</a></li> <li> <a href="http://uvadlc.github.io" rel="external nofollow noopener" target="_blank">UVA Deep Learning Course</a> MSc in Artificial Intelligence for the University of Amsterdam.</li> <li><a href="http://selfdrivingcars.mit.edu/" rel="external nofollow noopener" target="_blank">MIT 6.S094: Deep Learning for Self-Driving Cars</a></li> <li><a href="http://introtodeeplearning.com/" rel="external nofollow noopener" target="_blank">MIT 6.S191: Introduction to Deep Learning</a></li> <li><a href="http://rll.berkeley.edu/deeprlcourse/" rel="external nofollow noopener" target="_blank">Berkeley CS 294: Deep Reinforcement Learning</a></li> <li><a href="https://www.manning.com/livevideo/keras-in-motion" rel="external nofollow noopener" target="_blank">Keras in Motion video course</a></li> <li> <a href="http://course.fast.ai/" rel="external nofollow noopener" target="_blank">Practical Deep Learning For Coders</a> by Jeremy Howard - Fast.ai</li> <li> <a href="http://deeplearning.cs.cmu.edu/" rel="external nofollow noopener" target="_blank">Introduction to Deep Learning</a> by Prof. Bhiksha Raj (2017)</li> </ol> <h3 id="videos-and-lectures">Videos and Lectures</h3> <ol> <li> <a href="https://www.youtube.com/watch?v=RIkxVci-R4k" rel="external nofollow noopener" target="_blank">How To Create A Mind</a> By Ray Kurzweil</li> <li> <a href="https://www.youtube.com/watch?v=n1ViNeWhC24" rel="external nofollow noopener" target="_blank">Deep Learning, Self-Taught Learning and Unsupervised Feature Learning</a> By Andrew Ng</li> <li> <a href="https://www.youtube.com/watch?v=vShMxxqtDDs&amp;index=3&amp;list=PL78U8qQHXgrhP9aZraxTT5-X1RccTcUYT" rel="external nofollow noopener" target="_blank">Recent Developments in Deep Learning</a> By Geoff Hinton</li> <li> <a href="https://www.youtube.com/watch?v=sc-KbuZqGkI" rel="external nofollow noopener" target="_blank">The Unreasonable Effectiveness of Deep Learning</a> by Yann LeCun</li> <li> <a href="https://www.youtube.com/watch?v=4xsVFLnHC_0" rel="external nofollow noopener" target="_blank">Deep Learning of Representations</a> by Yoshua bengio</li> <li> <a href="https://www.youtube.com/watch?v=6ufPpZDmPKA" rel="external nofollow noopener" target="_blank">Principles of Hierarchical Temporal Memory</a> by Jeff Hawkins</li> <li> <a href="https://www.youtube.com/watch?v=2QJi0ArLq7s&amp;list=PL78U8qQHXgrhP9aZraxTT5-X1RccTcUYT" rel="external nofollow noopener" target="_blank">Machine Learning Discussion Group - Deep Learning w/ Stanford AI Lab</a> by Adam Coates</li> <li> <a href="http://vimeo.com/80821560" rel="external nofollow noopener" target="_blank">Making Sense of the World with Deep Learning</a> By Adam Coates</li> <li> <a href="https://www.youtube.com/watch?v=wZfVBwOO0-k" rel="external nofollow noopener" target="_blank">Demystifying Unsupervised Feature Learning </a> By Adam Coates</li> <li> <a href="https://www.youtube.com/watch?v=3boKlkPBckA" rel="external nofollow noopener" target="_blank">Visual Perception with Deep Learning</a> By Yann LeCun</li> <li> <a href="https://www.youtube.com/watch?v=AyzOUbkUf3M" rel="external nofollow noopener" target="_blank">The Next Generation of Neural Networks</a> By Geoffrey Hinton at GoogleTechTalks</li> <li> <a href="http://www.ted.com/talks/jeremy_howard_the_wonderful_and_terrifying_implications_of_computers_that_can_learn" rel="external nofollow noopener" target="_blank">The wonderful and terrifying implications of computers that can learn</a> By Jeremy Howard at TEDxBrussels</li> <li> <a href="http://web.stanford.edu/class/cs294a/handouts.html" rel="external nofollow noopener" target="_blank">Unsupervised Deep Learning - Stanford</a> by Andrew Ng in Stanford (2011)</li> <li> <a href="http://web.stanford.edu/class/cs224n/handouts/" rel="external nofollow noopener" target="_blank">Natural Language Processing</a> By Chris Manning in Stanford</li> <li> <a href="http://googleresearch.blogspot.com/2015/09/a-beginners-guide-to-deep-neural.html" rel="external nofollow noopener" target="_blank">A beginners Guide to Deep Neural Networks</a> By Natalie Hammel and Lorraine Yurshansky</li> <li> <a href="https://www.youtube.com/watch?v=czLI3oLDe8M" rel="external nofollow noopener" target="_blank">Deep Learning: Intelligence from Big Data</a> by Steve Jurvetson (and panel) at VLAB in Stanford.</li> <li> <a href="https://www.youtube.com/watch?v=FoO8qDB8gUU" rel="external nofollow noopener" target="_blank">Introduction to Artificial Neural Networks and Deep Learning</a> by Leo Isikdogan at Motorola Mobility HQ</li> <li> <a href="https://nips.cc/Conferences/2016/Schedule" rel="external nofollow noopener" target="_blank">NIPS 2016 lecture and workshop videos</a> - NIPS 2016</li> <li> <a href="https://www.youtube.com/watch?v=oS5fz_mHVz0&amp;list=PLWKotBjTDoLj3rXBL-nEIPRN9V3a9Cx07" rel="external nofollow noopener" target="_blank">Deep Learning Crash Course</a>: a series of mini-lectures by Leo Isikdogan on YouTube (2018)</li> <li> <a href="http://info.usherbrooke.ca/hlarochelle/neural_networks/content.html" rel="external nofollow noopener" target="_blank">Neural Networks</a>: by Hugo Larochelle.</li> </ol> <h3 id="tutorials">Tutorials</h3> <ol> <li><a href="http://deeplearning.stanford.edu/wiki/index.php/UFLDL_Tutorial" rel="external nofollow noopener" target="_blank">UFLDL Tutorial 1</a></li> <li><a href="http://ufldl.stanford.edu/tutorial/supervised/LinearRegression/" rel="external nofollow noopener" target="_blank">UFLDL Tutorial 2</a></li> <li><a href="http://www.socher.org/index.php/DeepLearningTutorial/DeepLearningTutorial" rel="external nofollow noopener" target="_blank">Deep Learning for NLP (without Magic)</a></li> <li><a href="http://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks" rel="external nofollow noopener" target="_blank">A Deep Learning Tutorial: From Perceptrons to Deep Networks</a></li> <li><a href="http://www.metacademy.org/roadmaps/rgrosse/deep_learning" rel="external nofollow noopener" target="_blank">Deep Learning from the Bottom up</a></li> <li><a href="http://deeplearning.net/tutorial/deeplearning.pdf" rel="external nofollow noopener" target="_blank">Theano Tutorial</a></li> <li><a href="http://uk.mathworks.com/help/pdf_doc/nnet/nnet_ug.pdf" rel="external nofollow noopener" target="_blank">Neural Networks for Matlab</a></li> <li><a href="http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/" rel="external nofollow noopener" target="_blank">Using convolutional neural nets to detect facial keypoints tutorial</a></li> <li><a href="https://github.com/clementfarabet/ipam-tutorials/tree/master/th_tutorials" rel="external nofollow noopener" target="_blank">Torch7 Tutorials</a></li> <li><a href="https://github.com/josephmisiti/machine-learning-module" rel="external nofollow noopener" target="_blank">The Best Machine Learning Tutorials On The Web</a></li> <li><a href="http://www.robots.ox.ac.uk/~vgg/practicals/cnn/index.html" rel="external nofollow noopener" target="_blank">VGG Convolutional Neural Networks Practical</a></li> <li><a href="https://github.com/nlintz/TensorFlow-Tutorials" rel="external nofollow noopener" target="_blank">TensorFlow tutorials</a></li> <li><a href="https://github.com/pkmital/tensorflow_tutorials" rel="external nofollow noopener" target="_blank">More TensorFlow tutorials</a></li> <li><a href="https://github.com/aymericdamien/TensorFlow-Examples" rel="external nofollow noopener" target="_blank">TensorFlow Python Notebooks</a></li> <li><a href="https://github.com/Vict0rSch/deep_learning" rel="external nofollow noopener" target="_blank">Keras and Lasagne Deep Learning Tutorials</a></li> <li><a href="https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition" rel="external nofollow noopener" target="_blank">Classification on raw time series in TensorFlow with a LSTM RNN</a></li> <li><a href="http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/" rel="external nofollow noopener" target="_blank">Using convolutional neural nets to detect facial keypoints tutorial</a></li> <li><a href="https://github.com/astorfi/TensorFlow-World" rel="external nofollow noopener" target="_blank">TensorFlow-World</a></li> <li><a href="https://www.manning.com/books/deep-learning-with-python" rel="external nofollow noopener" target="_blank">Deep Learning with Python</a></li> <li><a href="https://www.manning.com/books/grokking-deep-learning" rel="external nofollow noopener" target="_blank">Grokking Deep Learning</a></li> <li><a href="https://www.manning.com/books/deep-learning-for-search" rel="external nofollow noopener" target="_blank">Deep Learning for Search</a></li> <li><a href="https://blog.sicara.com/keras-tutorial-content-based-image-retrieval-convolutional-denoising-autoencoder-dc91450cc511" rel="external nofollow noopener" target="_blank">Keras Tutorial: Content Based Image Retrieval Using a Convolutional Denoising Autoencoder</a></li> <li><a href="https://github.com/yunjey/pytorch-tutorial" rel="external nofollow noopener" target="_blank">Pytorch Tutorial by Yunjey Choi</a></li> </ol> <h3 id="researchers">Researchers</h3> <ol> <li><a href="http://aaroncourville.wordpress.com" rel="external nofollow noopener" target="_blank">Aaron Courville</a></li> <li><a href="http://www.cs.toronto.edu/~asamir/" rel="external nofollow noopener" target="_blank">Abdel-rahman Mohamed</a></li> <li><a href="http://cs.stanford.edu/~acoates/" rel="external nofollow noopener" target="_blank">Adam Coates</a></li> <li><a href="http://research.microsoft.com/en-us/people/alexac/" rel="external nofollow noopener" target="_blank">Alex Acero</a></li> <li><a href="http://www.cs.utoronto.ca/~kriz/index.html" rel="external nofollow noopener" target="_blank"> Alex Krizhevsky </a></li> <li><a href="http://users.ics.aalto.fi/alexilin/" rel="external nofollow noopener" target="_blank"> Alexander Ilin </a></li> <li><a href="http://homepages.inf.ed.ac.uk/amos/" rel="external nofollow noopener" target="_blank"> Amos Storkey </a></li> <li><a href="http://cs.stanford.edu/~karpathy/" rel="external nofollow noopener" target="_blank"> Andrej Karpathy </a></li> <li><a href="http://www.stanford.edu/~asaxe/" rel="external nofollow noopener" target="_blank"> Andrew M. Saxe </a></li> <li><a href="http://www.cs.stanford.edu/people/ang/" rel="external nofollow noopener" target="_blank"> Andrew Ng </a></li> <li><a href="http://research.google.com/pubs/author37792.html" rel="external nofollow noopener" target="_blank"> Andrew W. Senior </a></li> <li><a href="http://www.gatsby.ucl.ac.uk/~amnih/" rel="external nofollow noopener" target="_blank"> Andriy Mnih </a></li> <li><a href="http://www.cs.nyu.edu/~naz/" rel="external nofollow noopener" target="_blank"> Ayse Naz Erkan </a></li> <li><a href="http://reslab.elis.ugent.be/benjamin" rel="external nofollow noopener" target="_blank"> Benjamin Schrauwen </a></li> <li><a href="https://www.cisuc.uc.pt/people/show/2020" rel="external nofollow noopener" target="_blank"> Bernardete Ribeiro </a></li> <li><a href="http://vision.caltech.edu/~bchen3/Site/Bo_David_Chen.html" rel="external nofollow noopener" target="_blank"> Bo David Chen </a></li> <li><a href="http://cs.nyu.edu/~ylan/" rel="external nofollow noopener" target="_blank"> Boureau Y-Lan </a></li> <li><a href="http://researcher.watson.ibm.com/researcher/view.php?person=us-bedk" rel="external nofollow noopener" target="_blank"> Brian Kingsbury </a></li> <li><a href="http://nlp.stanford.edu/~manning/" rel="external nofollow noopener" target="_blank"> Christopher Manning </a></li> <li><a href="http://www.clement.farabet.net/" rel="external nofollow noopener" target="_blank"> Clement Farabet </a></li> <li><a href="http://www.idsia.ch/~ciresan/" rel="external nofollow noopener" target="_blank"> Dan Claudiu Cireșan </a></li> <li><a href="http://serre-lab.clps.brown.edu/person/david-reichert/" rel="external nofollow noopener" target="_blank"> David Reichert </a></li> <li><a href="http://mil.engr.utk.edu/nmil/member/5.html" rel="external nofollow noopener" target="_blank"> Derek Rose </a></li> <li><a href="http://research.microsoft.com/en-us/people/dongyu/default.aspx" rel="external nofollow noopener" target="_blank"> Dong Yu </a></li> <li><a href="http://www.seas.upenn.edu/~wulsin/" rel="external nofollow noopener" target="_blank"> Drausin Wulsin </a></li> <li><a href="http://music.ece.drexel.edu/people/eschmidt" rel="external nofollow noopener" target="_blank"> Erik M. Schmidt </a></li> <li><a href="https://engineering.purdue.edu/BME/People/viewPersonById?resource_id=71333" rel="external nofollow noopener" target="_blank"> Eugenio Culurciello </a></li> <li><a href="http://research.microsoft.com/en-us/people/fseide/" rel="external nofollow noopener" target="_blank"> Frank Seide </a></li> <li><a href="http://homes.cs.washington.edu/~galen/" rel="external nofollow noopener" target="_blank"> Galen Andrew </a></li> <li><a href="http://www.cs.toronto.edu/~hinton/" rel="external nofollow noopener" target="_blank"> Geoffrey Hinton </a></li> <li><a href="http://www.cs.toronto.edu/~gdahl/" rel="external nofollow noopener" target="_blank"> George Dahl </a></li> <li><a href="http://www.uoguelph.ca/~gwtaylor/" rel="external nofollow noopener" target="_blank"> Graham Taylor </a></li> <li><a href="http://gregoire.montavon.name/" rel="external nofollow noopener" target="_blank"> Grégoire Montavon </a></li> <li><a href="http://personal-homepages.mis.mpg.de/montufar/" rel="external nofollow noopener" target="_blank"> Guido Francisco Montúfar </a></li> <li><a href="http://brainlogging.wordpress.com/" rel="external nofollow noopener" target="_blank"> Guillaume Desjardins </a></li> <li><a href="http://www.ais.uni-bonn.de/~schulz/" rel="external nofollow noopener" target="_blank"> Hannes Schulz </a></li> <li><a href="http://www.lri.fr/~hpaugam/" rel="external nofollow noopener" target="_blank"> Hélène Paugam-Moisy </a></li> <li><a href="http://web.eecs.umich.edu/~honglak/" rel="external nofollow noopener" target="_blank"> Honglak Lee </a></li> <li><a href="http://www.dmi.usherb.ca/~larocheh/index_en.html" rel="external nofollow noopener" target="_blank"> Hugo Larochelle </a></li> <li><a href="http://www.cs.toronto.edu/~ilya/" rel="external nofollow noopener" target="_blank"> Ilya Sutskever </a></li> <li><a href="http://mil.engr.utk.edu/nmil/member/2.html" rel="external nofollow noopener" target="_blank"> Itamar Arel </a></li> <li><a href="http://www.cs.toronto.edu/~jmartens/" rel="external nofollow noopener" target="_blank"> James Martens </a></li> <li><a href="http://www.jasonmorton.com/" rel="external nofollow noopener" target="_blank"> Jason Morton </a></li> <li><a href="http://www.thespermwhale.com/jaseweston/" rel="external nofollow noopener" target="_blank"> Jason Weston </a></li> <li><a href="http://research.google.com/pubs/jeff.html" rel="external nofollow noopener" target="_blank"> Jeff Dean </a></li> <li><a href="http://cs.stanford.edu/~jngiam/" rel="external nofollow noopener" target="_blank"> Jiquan Mgiam </a></li> <li><a href="http://www-etud.iro.umontreal.ca/~turian/" rel="external nofollow noopener" target="_blank"> Joseph Turian </a></li> <li><a href="http://aclab.ca/users/josh/index.html" rel="external nofollow noopener" target="_blank"> Joshua Matthew Susskind </a></li> <li><a href="http://www.idsia.ch/~juergen/" rel="external nofollow noopener" target="_blank"> Jürgen Schmidhuber </a></li> <li><a href="https://sites.google.com/site/blancousna/" rel="external nofollow noopener" target="_blank"> Justin A. Blanco </a></li> <li><a href="http://koray.kavukcuoglu.org/" rel="external nofollow noopener" target="_blank"> Koray Kavukcuoglu </a></li> <li><a href="http://users.ics.aalto.fi/kcho/" rel="external nofollow noopener" target="_blank"> KyungHyun Cho </a></li> <li><a href="http://research.microsoft.com/en-us/people/deng/" rel="external nofollow noopener" target="_blank"> Li Deng </a></li> <li><a href="http://www.kyb.tuebingen.mpg.de/nc/employee/details/lucas.html" rel="external nofollow noopener" target="_blank"> Lucas Theis </a></li> <li><a href="http://ludovicarnold.altervista.org/home/" rel="external nofollow noopener" target="_blank"> Ludovic Arnold </a></li> <li><a href="http://www.cs.nyu.edu/~ranzato/" rel="external nofollow noopener" target="_blank"> Marc’Aurelio Ranzato </a></li> <li><a href="http://aass.oru.se/~mlt/" rel="external nofollow noopener" target="_blank"> Martin Längkvist </a></li> <li><a href="http://mdenil.com/" rel="external nofollow noopener" target="_blank"> Misha Denil </a></li> <li><a href="http://www.cs.toronto.edu/~norouzi/" rel="external nofollow noopener" target="_blank"> Mohammad Norouzi </a></li> <li><a href="http://www.cs.ubc.ca/~nando/" rel="external nofollow noopener" target="_blank"> Nando de Freitas </a></li> <li><a href="http://www.cs.utoronto.ca/~ndjaitly/" rel="external nofollow noopener" target="_blank"> Navdeep Jaitly </a></li> <li><a href="http://nicolas.le-roux.name/" rel="external nofollow noopener" target="_blank"> Nicolas Le Roux </a></li> <li><a href="http://www.cs.toronto.edu/~nitish/" rel="external nofollow noopener" target="_blank"> Nitish Srivastava </a></li> <li><a href="https://www.cisuc.uc.pt/people/show/2028" rel="external nofollow noopener" target="_blank"> Noel Lopes </a></li> <li><a href="http://www.cs.berkeley.edu/~vinyals/" rel="external nofollow noopener" target="_blank"> Oriol Vinyals </a></li> <li><a href="http://www.iro.umontreal.ca/~vincentp" rel="external nofollow noopener" target="_blank"> Pascal Vincent </a></li> <li><a href="https://sites.google.com/site/drpngx/" rel="external nofollow noopener" target="_blank"> Patrick Nguyen </a></li> <li><a href="http://homes.cs.washington.edu/~pedrod/" rel="external nofollow noopener" target="_blank"> Pedro Domingos </a></li> <li><a href="http://homepages.inf.ed.ac.uk/pseries/" rel="external nofollow noopener" target="_blank"> Peggy Series </a></li> <li><a href="http://cs.nyu.edu/~sermanet" rel="external nofollow noopener" target="_blank"> Pierre Sermanet </a></li> <li><a href="http://www.cs.nyu.edu/~mirowski/" rel="external nofollow noopener" target="_blank"> Piotr Mirowski </a></li> <li><a href="http://ai.stanford.edu/~quocle/" rel="external nofollow noopener" target="_blank"> Quoc V. Le </a></li> <li><a href="http://bci.tugraz.at/scherer/" rel="external nofollow noopener" target="_blank"> Reinhold Scherer </a></li> <li><a href="http://www.socher.org/" rel="external nofollow noopener" target="_blank"> Richard Socher </a></li> <li><a href="http://cs.nyu.edu/~fergus/pmwiki/pmwiki.php" rel="external nofollow noopener" target="_blank"> Rob Fergus </a></li> <li><a href="http://mil.engr.utk.edu/nmil/member/19.html" rel="external nofollow noopener" target="_blank"> Robert Coop </a></li> <li><a href="http://homes.cs.washington.edu/~rcg/" rel="external nofollow noopener" target="_blank"> Robert Gens </a></li> <li><a href="http://people.csail.mit.edu/rgrosse/" rel="external nofollow noopener" target="_blank"> Roger Grosse </a></li> <li><a href="http://ronan.collobert.com/" rel="external nofollow noopener" target="_blank"> Ronan Collobert </a></li> <li><a href="http://www.utstat.toronto.edu/~rsalakhu/" rel="external nofollow noopener" target="_blank"> Ruslan Salakhutdinov </a></li> <li><a href="http://www.kyb.tuebingen.mpg.de/nc/employee/details/sgerwinn.html" rel="external nofollow noopener" target="_blank"> Sebastian Gerwinn </a></li> <li><a href="http://www.cmap.polytechnique.fr/~mallat/" rel="external nofollow noopener" target="_blank"> Stéphane Mallat </a></li> <li><a href="http://www.ais.uni-bonn.de/behnke/" rel="external nofollow noopener" target="_blank"> Sven Behnke </a></li> <li><a href="http://users.ics.aalto.fi/praiko/" rel="external nofollow noopener" target="_blank"> Tapani Raiko </a></li> <li><a href="https://sites.google.com/site/tsainath/" rel="external nofollow noopener" target="_blank"> Tara Sainath </a></li> <li><a href="http://www.cs.toronto.edu/~tijmen/" rel="external nofollow noopener" target="_blank"> Tijmen Tieleman </a></li> <li><a href="http://mil.engr.utk.edu/nmil/member/36.html" rel="external nofollow noopener" target="_blank"> Tom Karnowski </a></li> <li><a href="https://research.facebook.com/tomas-mikolov" rel="external nofollow noopener" target="_blank"> Tomáš Mikolov </a></li> <li><a href="http://www.idsia.ch/~meier/" rel="external nofollow noopener" target="_blank"> Ueli Meier </a></li> <li><a href="http://vincent.vanhoucke.com" rel="external nofollow noopener" target="_blank"> Vincent Vanhoucke </a></li> <li><a href="http://www.cs.toronto.edu/~vmnih/" rel="external nofollow noopener" target="_blank"> Volodymyr Mnih </a></li> <li><a href="http://yann.lecun.com/" rel="external nofollow noopener" target="_blank"> Yann LeCun </a></li> <li><a href="http://www.cs.toronto.edu/~tang/" rel="external nofollow noopener" target="_blank"> Yichuan Tang </a></li> <li><a href="http://www.iro.umontreal.ca/~bengioy/yoshua_en/index.html" rel="external nofollow noopener" target="_blank"> Yoshua Bengio </a></li> <li><a href="http://yota.ro/" rel="external nofollow noopener" target="_blank"> Yotaro Kubo </a></li> <li><a href="http://ai.stanford.edu/~wzou" rel="external nofollow noopener" target="_blank"> Youzhi (Will) Zou </a></li> <li><a href="http://vision.stanford.edu/feifeili" rel="external nofollow noopener" target="_blank"> Fei-Fei Li </a></li> <li><a href="https://research.google.com/pubs/105214.html" rel="external nofollow noopener" target="_blank"> Ian Goodfellow </a></li> <li><a href="http://www.site.uottawa.ca/~laganier/" rel="external nofollow noopener" target="_blank"> Robert Laganière </a></li> </ol> <h3 id="websites">WebSites</h3> <ol> <li><a href="http://deeplearning.net/" rel="external nofollow noopener" target="_blank">deeplearning.net</a></li> <li><a href="http://deeplearning.stanford.edu/" rel="external nofollow noopener" target="_blank">deeplearning.stanford.edu</a></li> <li><a href="http://nlp.stanford.edu/" rel="external nofollow noopener" target="_blank">nlp.stanford.edu</a></li> <li><a href="http://www.ai-junkie.com/ann/evolved/nnt1.html" rel="external nofollow noopener" target="_blank">ai-junkie.com</a></li> <li><a href="http://cs.brown.edu/research/ai/" rel="external nofollow noopener" target="_blank">cs.brown.edu/research/ai</a></li> <li><a href="http://www.eecs.umich.edu/ai/" rel="external nofollow noopener" target="_blank">eecs.umich.edu/ai</a></li> <li><a href="http://www.cs.utexas.edu/users/ai-lab/" rel="external nofollow noopener" target="_blank">cs.utexas.edu/users/ai-lab</a></li> <li><a href="http://www.cs.washington.edu/research/ai/" rel="external nofollow noopener" target="_blank">cs.washington.edu/research/ai</a></li> <li><a href="http://www.aiai.ed.ac.uk/" rel="external nofollow noopener" target="_blank">aiai.ed.ac.uk</a></li> <li><a href="http://www-aig.jpl.nasa.gov/" rel="external nofollow noopener" target="_blank">www-aig.jpl.nasa.gov</a></li> <li><a href="http://www.csail.mit.edu/" rel="external nofollow noopener" target="_blank">csail.mit.edu</a></li> <li><a href="http://cgi.cse.unsw.edu.au/~aishare/" rel="external nofollow noopener" target="_blank">cgi.cse.unsw.edu.au/~aishare</a></li> <li><a href="http://www.cs.rochester.edu/research/ai/" rel="external nofollow noopener" target="_blank">cs.rochester.edu/research/ai</a></li> <li><a href="http://www.ai.sri.com/" rel="external nofollow noopener" target="_blank">ai.sri.com</a></li> <li><a href="http://www.isi.edu/AI/isd.htm" rel="external nofollow noopener" target="_blank">isi.edu/AI/isd.htm</a></li> <li><a href="http://www.nrl.navy.mil/itd/aic/" rel="external nofollow noopener" target="_blank">nrl.navy.mil/itd/aic</a></li> <li><a href="http://hips.seas.harvard.edu/" rel="external nofollow noopener" target="_blank">hips.seas.harvard.edu</a></li> <li><a href="http://aiweekly.co" rel="external nofollow noopener" target="_blank">AI Weekly</a></li> <li><a href="http://www.stat.ucla.edu/~junhua.mao/m-RNN.html" rel="external nofollow noopener" target="_blank">stat.ucla.edu</a></li> <li><a href="http://deeplearning.cs.toronto.edu/i2t" rel="external nofollow noopener" target="_blank">deeplearning.cs.toronto.edu</a></li> <li><a href="http://jeffdonahue.com/lrcn/" rel="external nofollow noopener" target="_blank">jeffdonahue.com/lrcn/</a></li> <li><a href="http://www.visualqa.org/" rel="external nofollow noopener" target="_blank">visualqa.org</a></li> <li><a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/" rel="external nofollow noopener" target="_blank">www.mpi-inf.mpg.de/departments/computer-vision…</a></li> <li><a href="http://news.startup.ml/" rel="external nofollow noopener" target="_blank">Deep Learning News</a></li> <li><a href="https://medium.com/@ageitgey/" rel="external nofollow noopener" target="_blank">Machine Learning is Fun! Adam Geitgey’s Blog</a></li> <li><a href="http://yerevann.com/a-guide-to-deep-learning/" rel="external nofollow noopener" target="_blank">Guide to Machine Learning</a></li> <li><a href="https://spandan-madan.github.io/DeepLearningProject/" rel="external nofollow noopener" target="_blank">Deep Learning for Beginners</a></li> </ol> <h3 id="datasets">Datasets</h3> <ol> <li> <a href="http://yann.lecun.com/exdb/mnist/" rel="external nofollow noopener" target="_blank">MNIST</a> Handwritten digits</li> <li> <a href="http://ufldl.stanford.edu/housenumbers/" rel="external nofollow noopener" target="_blank">Google House Numbers</a> from street view</li> <li><a href="http://www.cs.toronto.edu/~kriz/cifar.html" rel="external nofollow noopener" target="_blank">CIFAR-10 and CIFAR-100</a></li> <li><a href="http://www.image-net.org/" rel="external nofollow noopener" target="_blank">IMAGENET</a></li> <li> <a href="http://groups.csail.mit.edu/vision/TinyImages/" rel="external nofollow noopener" target="_blank">Tiny Images</a> 80 Million tiny images6.</li> <li> <a href="https://yahooresearch.tumblr.com/post/89783581601/one-hundred-million-creative-commons-flickr-images" rel="external nofollow noopener" target="_blank">Flickr Data</a> 100 Million Yahoo dataset</li> <li><a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/" rel="external nofollow noopener" target="_blank">Berkeley Segmentation Dataset 500</a></li> <li><a href="http://archive.ics.uci.edu/ml/" rel="external nofollow noopener" target="_blank">UC Irvine Machine Learning Repository</a></li> <li><a href="http://nlp.cs.illinois.edu/HockenmaierGroup/Framing_Image_Description/KCCA.html" rel="external nofollow noopener" target="_blank">Flickr 8k</a></li> <li><a href="http://shannon.cs.illinois.edu/DenotationGraph/" rel="external nofollow noopener" target="_blank">Flickr 30k</a></li> <li><a href="http://mscoco.org/home/" rel="external nofollow noopener" target="_blank">Microsoft COCO</a></li> <li><a href="http://www.visualqa.org/" rel="external nofollow noopener" target="_blank">VQA</a></li> <li><a href="http://www.cs.toronto.edu/~mren/imageqa/data/cocoqa/" rel="external nofollow noopener" target="_blank">Image QA</a></li> <li><a href="http://www.uk.research.att.com/facedatabase.html" rel="external nofollow noopener" target="_blank">AT&amp;T Laboratories Cambridge face database</a></li> <li><a href="http://xtreme.gsfc.nasa.gov" rel="external nofollow noopener" target="_blank">AVHRR Pathfinder</a></li> <li> <a href="http://www.anc.ed.ac.uk/~amos/afreightdata.html" rel="external nofollow noopener" target="_blank">Air Freight</a> - The Air Freight data set is a ray-traced image sequence along with ground truth segmentation based on textural characteristics. (455 images + GT, each 160x120 pixels). (Formats: PNG)</li> <li> <a href="http://www.science.uva.nl/~aloi/" rel="external nofollow noopener" target="_blank">Amsterdam Library of Object Images</a> - ALOI is a color image collection of one-thousand small objects, recorded for scientific purposes. In order to capture the sensory variation in object recordings, we systematically varied viewing angle, illumination angle, and illumination color for each object, and additionally captured wide-baseline stereo images. We recorded over a hundred images of each object, yielding a total of 110,250 images for the collection. (Formats: png)</li> <li> <a href="http://www.imm.dtu.dk/~aam/" rel="external nofollow noopener" target="_blank">Annotated face, hand, cardiac &amp; meat images</a> - Most images &amp; annotations are supplemented by various ASM/AAM analyses using the AAM-API. (Formats: bmp,asf)</li> <li><a href="http://www.imm.dtu.dk/image/" rel="external nofollow noopener" target="_blank">Image Analysis and Computer Graphics</a></li> <li> <a href="http://www.cog.brown.edu/~tarr/stimuli.html" rel="external nofollow noopener" target="_blank">Brown University Stimuli</a> - A variety of datasets including geons, objects, and “greebles”. Good for testing recognition algorithms. (Formats: pict)</li> <li> <a href="http://homepages.inf.ed.ac.uk/rbf/CAVIARDATA1/" rel="external nofollow noopener" target="_blank">CAVIAR video sequences of mall and public space behavior</a> - 90K video frames in 90 sequences of various human activities, with XML ground truth of detection and behavior classification (Formats: MPEG2 &amp; JPEG)</li> <li><a href="http://www.ipab.inf.ed.ac.uk/mvu/" rel="external nofollow noopener" target="_blank">Machine Vision Unit</a></li> <li> <a href="http://www.cs.waikato.ac.nz/~singlis/ccitt.html" rel="external nofollow noopener" target="_blank">CCITT Fax standard images</a> - 8 images (Formats: gif)</li> <li> <a href="cil-ster.html">CMU CIL’s Stereo Data with Ground Truth</a> - 3 sets of 11 images, including color tiff images with spectroradiometry (Formats: gif, tiff)</li> <li> <a href="http://www.ri.cmu.edu/projects/project_418.html" rel="external nofollow noopener" target="_blank">CMU PIE Database</a> - A database of 41,368 face images of 68 people captured under 13 poses, 43 illuminations conditions, and with 4 different expressions.</li> <li> <a href="http://www.ius.cs.cmu.edu/idb/" rel="external nofollow noopener" target="_blank">CMU VASC Image Database</a> - Images, sequences, stereo pairs (thousands of images) (Formats: Sun Rasterimage)</li> <li> <a href="http://www.vision.caltech.edu/html-files/archive.html" rel="external nofollow noopener" target="_blank">Caltech Image Database</a> - about 20 images - mostly top-down views of small objects and toys. (Formats: GIF)</li> <li> <a href="http://www.cs.columbia.edu/CAVE/curet/" rel="external nofollow noopener" target="_blank">Columbia-Utrecht Reflectance and Texture Database</a> - Texture and reflectance measurements for over 60 samples of 3D texture, observed with over 200 different combinations of viewing and illumination directions. (Formats: bmp)</li> <li> <a href="http://www.cs.sfu.ca/~colour/data/index.html" rel="external nofollow noopener" target="_blank">Computational Colour Constancy Data</a> - A dataset oriented towards computational color constancy, but useful for computer vision in general. It includes synthetic data, camera sensor data, and over 700 images. (Formats: tiff)</li> <li><a href="http://www.cs.sfu.ca/~colour/" rel="external nofollow noopener" target="_blank">Computational Vision Lab</a></li> <li> <a href="http://www.cs.washington.edu/research/imagedatabase/groundtruth/" rel="external nofollow noopener" target="_blank">Content-based image retrieval database</a> - 11 sets of color images for testing algorithms for content-based retrieval. Most sets have a description file with names of objects in each image. (Formats: jpg)</li> <li><a href="http://www.cs.washington.edu/research/imagedatabase/" rel="external nofollow noopener" target="_blank">Efficient Content-based Retrieval Group</a></li> <li> <a href="http://ls7-www.cs.uni-dortmund.de/~peters/pages/research/modeladaptsys/modeladaptsys_vba_rov.html" rel="external nofollow noopener" target="_blank">Densely Sampled View Spheres</a> - Densely sampled view spheres - upper half of the view sphere of two toy objects with 2500 images each. (Formats: tiff)</li> <li><a href="http://ls7-www.cs.uni-dortmund.de/" rel="external nofollow noopener" target="_blank">Computer Science VII (Graphical Systems)</a></li> <li> <a href="https://web-beta.archive.org/web/20011216051535/vision.psych.umn.edu/www/kersten-lab/demos/digitalembryo.html" rel="external nofollow noopener" target="_blank">Digital Embryos</a> - Digital embryos are novel objects which may be used to develop and test object recognition systems. They have an organic appearance. (Formats: various formats are available on request)</li> <li><a href="http://vision.psych.umn.edu/www/kersten-lab/kersten-lab.html" rel="external nofollow noopener" target="_blank">Univerity of Minnesota Vision Lab</a></li> <li> <a href="http://www.gastrointestinalatlas.com" rel="external nofollow noopener" target="_blank">El Salvador Atlas of Gastrointestinal VideoEndoscopy</a> - Images and Videos of his-res of studies taken from Gastrointestinal Video endoscopy. (Formats: jpg, mpg, gif)</li> <li> <a href="http://sting.cycollege.ac.cy/~alanitis/fgnetaging/index.htm" rel="external nofollow noopener" target="_blank">FG-NET Facial Aging Database</a> - Database contains 1002 face images showing subjects at different ages. (Formats: jpg)</li> <li> <a href="http://bias.csr.unibo.it/fvc2000/" rel="external nofollow noopener" target="_blank">FVC2000 Fingerprint Databases</a> - FVC2000 is the First International Competition for Fingerprint Verification Algorithms. Four fingerprint databases constitute the FVC2000 benchmark (3520 fingerprints in all).</li> <li> <a href="http://bias.csr.unibo.it/research/biolab" rel="external nofollow noopener" target="_blank">Biometric Systems Lab</a> - University of Bologna</li> <li> <a href="http://www.fg-net.org" rel="external nofollow noopener" target="_blank">Face and Gesture images and image sequences</a> - Several image datasets of faces and gestures that are ground truth annotated for benchmarking</li> <li> <a href="http://www-i6.informatik.rwth-aachen.de/~dreuw/database.html" rel="external nofollow noopener" target="_blank">German Fingerspelling Database</a> - The database contains 35 gestures and consists of 1400 image sequences that contain gestures of 20 different persons recorded under non-uniform daylight lighting conditions. (Formats: mpg,jpg)</li> <li><a href="http://www-i6.informatik.rwth-aachen.de/" rel="external nofollow noopener" target="_blank">Language Processing and Pattern Recognition</a></li> <li> <a href="http://hlab.phys.rug.nl/archive.html" rel="external nofollow noopener" target="_blank">Groningen Natural Image Database</a> - 4000+ 1536x1024 (16 bit) calibrated outdoor images (Formats: homebrew)</li> <li> <a href="http://www.icg.tu-graz.ac.at/~schindler/Data" rel="external nofollow noopener" target="_blank">ICG Testhouse sequence</a> - 2 turntable sequences from ifferent viewing heights, 36 images each, resolution 1000x750, color (Formats: PPM)</li> <li><a href="http://www.icg.tu-graz.ac.at" rel="external nofollow noopener" target="_blank">Institute of Computer Graphics and Vision</a></li> <li> <a href="http://www.ien.it/is/vislib/" rel="external nofollow noopener" target="_blank">IEN Image Library</a> - 1000+ images, mostly outdoor sequences (Formats: raw, ppm)</li> <li> <a href="http://www-rocq.inria.fr/~tarel/syntim/images.html" rel="external nofollow noopener" target="_blank">INRIA’s Syntim images database</a> - 15 color image of simple objects (Formats: gif)</li> <li><a href="http://www.inria.fr/" rel="external nofollow noopener" target="_blank">INRIA</a></li> <li> <a href="http://www-rocq.inria.fr/~tarel/syntim/paires.html" rel="external nofollow noopener" target="_blank">INRIA’s Syntim stereo databases</a> - 34 calibrated color stereo pairs (Formats: gif)</li> <li> <a href="http://www.ece.ncsu.edu/imaging/Archives/ImageDataBase/index.html" rel="external nofollow noopener" target="_blank">Image Analysis Laboratory</a> - Images obtained from a variety of imaging modalities – raw CFA images, range images and a host of “medical images”. (Formats: homebrew)</li> <li><a href="http://www.ece.ncsu.edu/imaging" rel="external nofollow noopener" target="_blank">Image Analysis Laboratory</a></li> <li> <a href="http://www.prip.tuwien.ac.at/prip/image.html" rel="external nofollow noopener" target="_blank">Image Database</a> - An image database including some textures</li> <li> <a href="http://www.mis.atr.co.jp/~mlyons/jaffe.html" rel="external nofollow noopener" target="_blank">JAFFE Facial Expression Image Database</a> - The JAFFE database consists of 213 images of Japanese female subjects posing 6 basic facial expressions as well as a neutral pose. Ratings on emotion adjectives are also available, free of charge, for research purposes. (Formats: TIFF Grayscale images.)</li> <li><a href="http://www.mic.atr.co.jp/" rel="external nofollow noopener" target="_blank">ATR Research, Kyoto, Japan</a></li> <li> <a href="ftp://ftp.vislist.com/IMAGERY/JISCT/">JISCT Stereo Evaluation</a> - 44 image pairs. These data have been used in an evaluation of stereo analysis, as described in the April 1993 ARPA Image Understanding Workshop paper ``The JISCT Stereo Evaluation’’ by R.C.Bolles, H.H.Baker, and M.J.Hannah, 263–274 (Formats: SSI)</li> <li> <a href="http://www-white.media.mit.edu/vismod/imagery/VisionTexture/vistex.html" rel="external nofollow noopener" target="_blank">MIT Vision Texture</a> - Image archive (100+ images) (Formats: ppm)</li> <li> <a href="ftp://whitechapel.media.mit.edu/pub/images">MIT face images and more</a> - hundreds of images (Formats: homebrew)</li> <li> <a href="http://vision.cse.psu.edu/book/testbed/images/" rel="external nofollow noopener" target="_blank">Machine Vision</a> - Images from the textbook by Jain, Kasturi, Schunck (20+ images) (Formats: GIF TIFF)</li> <li> <a href="http://marathon.csee.usf.edu/Mammography/Database.html" rel="external nofollow noopener" target="_blank">Mammography Image Databases</a> - 100 or more images of mammograms with ground truth. Additional images available by request, and links to several other mammography databases are provided. (Formats: homebrew)</li> <li> <a href="ftp://ftp.cps.msu.edu/pub/prip">ftp://ftp.cps.msu.edu/pub/prip</a> - many images (Formats: unknown)</li> <li> <a href="http://www.middlebury.edu/stereo/data.html" rel="external nofollow noopener" target="_blank">Middlebury Stereo Data Sets with Ground Truth</a> - Six multi-frame stereo data sets of scenes containing planar regions. Each data set contains 9 color images and subpixel-accuracy ground-truth data. (Formats: ppm)</li> <li> <a href="http://www.middlebury.edu/stereo" rel="external nofollow noopener" target="_blank">Middlebury Stereo Vision Research Page</a> - Middlebury College</li> <li> <a href="http://ltpwww.gsfc.nasa.gov/MODIS/MAS/" rel="external nofollow noopener" target="_blank">Modis Airborne simulator, Gallery and data set</a> - High Altitude Imagery from around the world for environmental modeling in support of NASA EOS program (Formats: JPG and HDF)</li> <li> <a href="ftp://sequoyah.ncsl.nist.gov/pub/databases/data">NIST Fingerprint and handwriting</a> - datasets - thousands of images (Formats: unknown)</li> <li> <a href="ftp://ftp.cs.columbia.edu/jpeg/other/uuencoded">NIST Fingerprint data</a> - compressed multipart uuencoded tar file</li> <li> <a href="http://www.nlm.nih.gov/research/visible/visible_human.html" rel="external nofollow noopener" target="_blank">NLM HyperDoc Visible Human Project</a> - Color, CAT and MRI image samples - over 30 images (Formats: jpeg)</li> <li> <a href="http://www.designrepository.org" rel="external nofollow noopener" target="_blank">National Design Repository</a> - Over 55,000 3D CAD and solid models of (mostly) mechanical/machined engineerign designs. (Formats: gif,vrml,wrl,stp,sat)</li> <li><a href="http://gicl.mcs.drexel.edu" rel="external nofollow noopener" target="_blank">Geometric &amp; Intelligent Computing Laboratory</a></li> <li> <a href="http://eewww.eng.ohio-state.edu/~flynn/3DDB/Models/" rel="external nofollow noopener" target="_blank">OSU (MSU) 3D Object Model Database</a> - several sets of 3D object models collected over several years to use in object recognition research (Formats: homebrew, vrml)</li> <li> <a href="http://eewww.eng.ohio-state.edu/~flynn/3DDB/RID/" rel="external nofollow noopener" target="_blank">OSU (MSU/WSU) Range Image Database</a> - Hundreds of real and synthetic images (Formats: gif, homebrew)</li> <li> <a href="http://sampl.eng.ohio-state.edu/~sampl/database.htm" rel="external nofollow noopener" target="_blank">OSU/SAMPL Database: Range Images, 3D Models, Stills, Motion Sequences</a> - Over 1000 range images, 3D object models, still images and motion sequences (Formats: gif, ppm, vrml, homebrew)</li> <li><a href="http://sampl.eng.ohio-state.edu" rel="external nofollow noopener" target="_blank">Signal Analysis and Machine Perception Laboratory</a></li> <li> <a href="http://www.cs.otago.ac.nz/research/vision/Research/OpticalFlow/opticalflow.html" rel="external nofollow noopener" target="_blank">Otago Optical Flow Evaluation Sequences</a> - Synthetic and real sequences with machine-readable ground truth optical flow fields, plus tools to generate ground truth for new sequences. (Formats: ppm,tif,homebrew)</li> <li><a href="http://www.cs.otago.ac.nz/research/vision/index.html" rel="external nofollow noopener" target="_blank">Vision Research Group</a></li> <li> <a href="ftp://ftp.limsi.fr/pub/quenot/opflow/testdata/piv/">ftp://ftp.limsi.fr/pub/quenot/opflow/testdata/piv/</a> - Real and synthetic image sequences used for testing a Particle Image Velocimetry application. These images may be used for the test of optical flow and image matching algorithms. (Formats: pgm (raw))</li> <li><a href="http://www.limsi.fr/Recherche/IMM/PageIMM.html" rel="external nofollow noopener" target="_blank">LIMSI-CNRS/CHM/IMM/vision</a></li> <li><a href="http://www.limsi.fr/" rel="external nofollow noopener" target="_blank">LIMSI-CNRS</a></li> <li> <a href="http://www.taurusstudio.net/research/pmtexdb/index.htm" rel="external nofollow noopener" target="_blank">Photometric 3D Surface Texture Database</a> - This is the first 3D texture database which provides both full real surface rotations and registered photometric stereo data (30 textures, 1680 images). (Formats: TIFF)</li> <li> <a href="http://www.cee.hw.ac.uk/~mtc/sofa" rel="external nofollow noopener" target="_blank">SEQUENCES FOR OPTICAL FLOW ANALYSIS (SOFA)</a> - 9 synthetic sequences designed for testing motion analysis applications, including full ground truth of motion and camera parameters. (Formats: gif)</li> <li><a href="http://www.cee.hw.ac.uk/~mtc/research.html" rel="external nofollow noopener" target="_blank">Computer Vision Group</a></li> <li> <a href="http://www.nada.kth.se/~zucch/CAMERA/PUB/seq.html" rel="external nofollow noopener" target="_blank">Sequences for Flow Based Reconstruction</a> - synthetic sequence for testing structure from motion algorithms (Formats: pgm)</li> <li> <a href="http://www-dbv.cs.uni-bonn.de/stereo_data/" rel="external nofollow noopener" target="_blank">Stereo Images with Ground Truth Disparity and Occlusion</a> - a small set of synthetic images of a hallway with varying amounts of noise added. Use these images to benchmark your stereo algorithm. (Formats: raw, viff (khoros), or tiff)</li> <li> <a href="http://range.informatik.uni-stuttgart.de" rel="external nofollow noopener" target="_blank">Stuttgart Range Image Database</a> - A collection of synthetic range images taken from high-resolution polygonal models available on the web (Formats: homebrew)</li> <li><a href="http://www.informatik.uni-stuttgart.de/ipvr/bv/bv_home_engl.html" rel="external nofollow noopener" target="_blank">Department Image Understanding</a></li> <li> <a href="http://www2.ece.ohio-state.edu/~aleix/ARdatabase.html" rel="external nofollow noopener" target="_blank">The AR Face Database</a> - Contains over 4,000 color images corresponding to 126 people’s faces (70 men and 56 women). Frontal views with variations in facial expressions, illumination, and occlusions. (Formats: RAW (RGB 24-bit))</li> <li><a href="http://rvl.www.ecn.purdue.edu/RVL/" rel="external nofollow noopener" target="_blank">Purdue Robot Vision Lab</a></li> <li> <a href="http://web.mit.edu/torralba/www/database.html" rel="external nofollow noopener" target="_blank">The MIT-CSAIL Database of Objects and Scenes</a> - Database for testing multiclass object detection and scene recognition algorithms. Over 72,000 images with 2873 annotated frames. More than 50 annotated object classes. (Formats: jpg)</li> <li> <a href="http://rvl1.ecn.purdue.edu/RVL/specularity_database/" rel="external nofollow noopener" target="_blank">The RVL SPEC-DB (SPECularity DataBase)</a> - A collection of over 300 real images of 100 objects taken under three different illuminaiton conditions (Diffuse/Ambient/Directed). – Use these images to test algorithms for detecting and compensating specular highlights in color images. (Formats: TIFF )</li> <li><a href="http://rvl1.ecn.purdue.edu/RVL/" rel="external nofollow noopener" target="_blank">Robot Vision Laboratory</a></li> <li> <a href="http://xm2vtsdb.ee.surrey.ac.uk" rel="external nofollow noopener" target="_blank">The Xm2vts database</a> - The XM2VTSDB contains four digital recordings of 295 people taken over a period of four months. This database contains both image and video data of faces.</li> <li><a href="http://www.ee.surrey.ac.uk/Research/CVSSP" rel="external nofollow noopener" target="_blank">Centre for Vision, Speech and Signal Processing</a></li> <li> <a href="http://i21www.ira.uka.de/image_sequences" rel="external nofollow noopener" target="_blank">Traffic Image Sequences and ‘Marbled Block’ Sequence</a> - thousands of frames of digitized traffic image sequences as well as the ‘Marbled Block’ sequence (grayscale images) (Formats: GIF)</li> <li><a href="http://i21www.ira.uka.de" rel="external nofollow noopener" target="_blank">IAKS/KOGS</a></li> <li> <a href="ftp://ftp.iam.unibe.ch/pub/Images/FaceImages">U Bern Face images</a> - hundreds of images (Formats: Sun rasterfile)</li> <li> <a href="ftp://freebie.engin.umich.edu/pub/misc/textures">U Michigan textures</a> (Formats: compressed raw)</li> <li> <a href="http://www.ee.oulu.fi/~olli/Projects/Lumber.Grading.html" rel="external nofollow noopener" target="_blank">U Oulu wood and knots database</a> - Includes classifications - 1000+ color images (Formats: ppm)</li> <li> <a href="http://vision.doc.ntu.ac.uk/datasets/UCID/ucid.html" rel="external nofollow noopener" target="_blank">UCID - an Uncompressed Colour Image Database</a> - a benchmark database for image retrieval with predefined ground truth. (Formats: tiff)</li> <li> <a href="http://vis-www.cs.umass.edu/~vislib/" rel="external nofollow noopener" target="_blank">UMass Vision Image Archive</a> - Large image database with aerial, space, stereo, medical images and more. (Formats: homebrew)</li> <li> <a href="ftp://sunsite.unc.edu/pub/academic/computer-science/virtual-reality/3d">UNC’s 3D image database</a> - many images (Formats: GIF)</li> <li> <a href="http://marathon.csee.usf.edu/range/seg-comp/SegComp.html" rel="external nofollow noopener" target="_blank">USF Range Image Data with Segmentation Ground Truth</a> - 80 image sets (Formats: Sun rasterimage)</li> <li> <a href="http://www.ee.oulu.fi/research/imag/color/pbfd.html" rel="external nofollow noopener" target="_blank">University of Oulu Physics-based Face Database</a> - contains color images of faces under different illuminants and camera calibration conditions as well as skin spectral reflectance measurements of each person.</li> <li><a href="http://www.ee.oulu.fi/mvmp/" rel="external nofollow noopener" target="_blank">Machine Vision and Media Processing Unit</a></li> <li> <a href="http://www.outex.oulu.fi" rel="external nofollow noopener" target="_blank">University of Oulu Texture Database</a> - Database of 320 surface textures, each captured under three illuminants, six spatial resolutions and nine rotation angles. A set of test suites is also provided so that texture segmentation, classification, and retrieval algorithms can be tested in a standard manner. (Formats: bmp, ras, xv)</li> <li><a href="http://www.ee.oulu.fi/mvg" rel="external nofollow noopener" target="_blank">Machine Vision Group</a></li> <li> <a href="ftp://ftp.uu.net/published/usenix/faces">Usenix face database</a> - Thousands of face images from many different sites (circa 994)</li> <li> <a href="http://www-prima.inrialpes.fr/Prima/hall/view_sphere.html" rel="external nofollow noopener" target="_blank">View Sphere Database</a> - Images of 8 objects seen from many different view points. The view sphere is sampled using a geodesic with 172 images/sphere. Two sets for training and testing are available. (Formats: ppm)</li> <li><a href="http://www-prima.inrialpes.fr/Prima/" rel="external nofollow noopener" target="_blank">PRIMA, GRAVIR</a></li> <li> <a href="ftp://ftp.vislist.com/IMAGERY/">Vision-list Imagery Archive</a> - Many images, many formats</li> <li> <a href="http://www.cs.cmu.edu/~owenc/word.htm" rel="external nofollow noopener" target="_blank">Wiry Object Recognition Database</a> - Thousands of images of a cart, ladder, stool, bicycle, chairs, and cluttered scenes with ground truth labelings of edges and regions. (Formats: jpg)</li> <li><a href="http://www.cs.cmu.edu/0.000000E+003dvision/" rel="external nofollow noopener" target="_blank">3D Vision Group</a></li> <li> <a href="http://cvc.yale.edu/projects/yalefaces/yalefaces.html" rel="external nofollow noopener" target="_blank">Yale Face Database</a> - 165 images (15 individuals) with different lighting, expression, and occlusion configurations.</li> <li> <a href="http://cvc.yale.edu/projects/yalefacesB/yalefacesB.html" rel="external nofollow noopener" target="_blank">Yale Face Database B</a> - 5760 single light source images of 10 subjects each seen under 576 viewing conditions (9 poses x 64 illumination conditions). (Formats: PGM)</li> <li><a href="http://cvc.yale.edu/" rel="external nofollow noopener" target="_blank">Center for Computational Vision and Control</a></li> <li> <a href="https://github.com/deepmind/rc-data" rel="external nofollow noopener" target="_blank">DeepMind QA Corpus</a> - Textual QA corpus from CNN and DailyMail. More than 300K documents in total. <a href="http://arxiv.org/abs/1506.03340" rel="external nofollow noopener" target="_blank">Paper</a> for reference.</li> <li> <a href="https://research.google.com/youtube8m/" rel="external nofollow noopener" target="_blank">YouTube-8M Dataset</a> - YouTube-8M is a large-scale labeled video dataset that consists of 8 million YouTube video IDs and associated labels from a diverse vocabulary of 4800 visual entities.</li> <li> <a href="https://github.com/openimages/dataset" rel="external nofollow noopener" target="_blank">Open Images dataset</a> - Open Images is a dataset of ~9 million URLs to images that have been annotated with labels spanning over 6000 categories.</li> <li> <a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html#devkit" rel="external nofollow noopener" target="_blank">Visual Object Classes Challenge 2012 (VOC2012)</a> - VOC2012 dataset containing 12k images with 20 annotated classes for object detection and segmentation.</li> <li> <a href="https://github.com/zalandoresearch/fashion-mnist" rel="external nofollow noopener" target="_blank">Fashion-MNIST</a> - MNIST like fashion product dataset consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.</li> <li> <a href="http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html" rel="external nofollow noopener" target="_blank">Large-scale Fashion (DeepFashion) Database</a> - Contains over 800,000 diverse fashion images. Each image in this dataset is labeled with 50 categories, 1,000 descriptive attributes, bounding box and clothing landmarks</li> </ol> <h3 id="conferences">Conferences</h3> <ol> <li><a href="http://cvpr2018.thecvf.com" rel="external nofollow noopener" target="_blank">CVPR - IEEE Conference on Computer Vision and Pattern Recognition</a></li> <li><a href="http://celweb.vuse.vanderbilt.edu/aamas18/" rel="external nofollow noopener" target="_blank">AAMAS - International Joint Conference on Autonomous Agents and Multiagent Systems</a></li> <li><a href="https://www.ijcai-18.org/" rel="external nofollow noopener" target="_blank">IJCAI - International Joint Conference on Artificial Intelligence</a></li> <li><a href="https://icml.cc" rel="external nofollow noopener" target="_blank">ICML - International Conference on Machine Learning</a></li> <li><a href="http://www.ecmlpkdd2018.org" rel="external nofollow noopener" target="_blank">ECML - European Conference on Machine Learning</a></li> <li><a href="http://www.kdd.org/kdd2018/" rel="external nofollow noopener" target="_blank">KDD - Knowledge Discovery and Data Mining</a></li> <li><a href="https://nips.cc/Conferences/2018" rel="external nofollow noopener" target="_blank">NIPS - Neural Information Processing Systems</a></li> <li><a href="https://conferences.oreilly.com/artificial-intelligence/ai-ny" rel="external nofollow noopener" target="_blank">O’Reilly AI Conference - O’Reilly Artificial Intelligence Conference</a></li> <li><a href="https://www.waset.org/conference/2018/07/istanbul/ICDM" rel="external nofollow noopener" target="_blank">ICDM - International Conference on Data Mining</a></li> <li><a href="http://iccv2017.thecvf.com" rel="external nofollow noopener" target="_blank">ICCV - International Conference on Computer Vision</a></li> <li><a href="https://www.aaai.org" rel="external nofollow noopener" target="_blank">AAAI - Association for the Advancement of Artificial Intelligence</a></li> </ol> <h3 id="frameworks">Frameworks</h3> <ol> <li><a href="http://caffe.berkeleyvision.org/" rel="external nofollow noopener" target="_blank">Caffe</a></li> <li><a href="http://torch.ch/" rel="external nofollow noopener" target="_blank">Torch7</a></li> <li><a href="http://deeplearning.net/software/theano/" rel="external nofollow noopener" target="_blank">Theano</a></li> <li><a href="https://code.google.com/p/cuda-convnet2/" rel="external nofollow noopener" target="_blank">cuda-convnet</a></li> <li><a href="https://github.com/karpathy/convnetjs" rel="external nofollow noopener" target="_blank">convetjs</a></li> <li><a href="http://libccv.org/doc/doc-convnet/" rel="external nofollow noopener" target="_blank">Ccv</a></li> <li><a href="http://numenta.org/nupic.html" rel="external nofollow noopener" target="_blank">NuPIC</a></li> <li><a href="http://deeplearning4j.org/" rel="external nofollow noopener" target="_blank">DeepLearning4J</a></li> <li><a href="https://github.com/harthur/brain" rel="external nofollow noopener" target="_blank">Brain</a></li> <li><a href="https://github.com/rasmusbergpalm/DeepLearnToolbox" rel="external nofollow noopener" target="_blank">DeepLearnToolbox</a></li> <li><a href="https://github.com/nitishsrivastava/deepnet" rel="external nofollow noopener" target="_blank">Deepnet</a></li> <li><a href="https://github.com/andersbll/deeppy" rel="external nofollow noopener" target="_blank">Deeppy</a></li> <li><a href="https://github.com/ivan-vasilev/neuralnetworks" rel="external nofollow noopener" target="_blank">JavaNN</a></li> <li><a href="https://github.com/hannes-brt/hebel" rel="external nofollow noopener" target="_blank">hebel</a></li> <li><a href="https://github.com/pluskid/Mocha.jl" rel="external nofollow noopener" target="_blank">Mocha.jl</a></li> <li><a href="https://github.com/guoding83128/OpenDL" rel="external nofollow noopener" target="_blank">OpenDL</a></li> <li><a href="https://developer.nvidia.com/cuDNN" rel="external nofollow noopener" target="_blank">cuDNN</a></li> <li><a href="http://melisgl.github.io/mgl-pax-world/mgl-manual.html" rel="external nofollow noopener" target="_blank">MGL</a></li> <li><a href="https://github.com/denizyuret/Knet.jl" rel="external nofollow noopener" target="_blank">Knet.jl</a></li> <li><a href="https://github.com/NVIDIA/DIGITS" rel="external nofollow noopener" target="_blank">Nvidia DIGITS - a web app based on Caffe</a></li> <li><a href="https://github.com/NervanaSystems/neon" rel="external nofollow noopener" target="_blank">Neon - Python based Deep Learning Framework</a></li> <li><a href="http://keras.io" rel="external nofollow noopener" target="_blank">Keras - Theano based Deep Learning Library</a></li> <li><a href="http://chainer.org/" rel="external nofollow noopener" target="_blank">Chainer - A flexible framework of neural networks for deep learning</a></li> <li><a href="http://rnnlm.org/" rel="external nofollow noopener" target="_blank">RNNLM Toolkit</a></li> <li><a href="http://sourceforge.net/p/rnnl/wiki/Home/" rel="external nofollow noopener" target="_blank">RNNLIB - A recurrent neural network library</a></li> <li><a href="https://github.com/karpathy/char-rnn" rel="external nofollow noopener" target="_blank">char-rnn</a></li> <li><a href="https://github.com/vlfeat/matconvnet" rel="external nofollow noopener" target="_blank">MatConvNet: CNNs for MATLAB</a></li> <li><a href="https://github.com/dmlc/minerva" rel="external nofollow noopener" target="_blank">Minerva - a fast and flexible tool for deep learning on multi-GPU</a></li> <li><a href="https://github.com/IDSIA/brainstorm" rel="external nofollow noopener" target="_blank">Brainstorm - Fast, flexible and fun neural networks.</a></li> <li><a href="https://github.com/tensorflow/tensorflow" rel="external nofollow noopener" target="_blank">Tensorflow - Open source software library for numerical computation using data flow graphs</a></li> <li><a href="https://github.com/Microsoft/DMTK" rel="external nofollow noopener" target="_blank">DMTK - Microsoft Distributed Machine Learning Tookit</a></li> <li><a href="https://github.com/google/skflow" rel="external nofollow noopener" target="_blank">Scikit Flow - Simplified interface for TensorFlow (mimicking Scikit Learn)</a></li> <li><a href="https://github.com/dmlc/mxnet/" rel="external nofollow noopener" target="_blank">MXnet - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning framework</a></li> <li><a href="https://github.com/Samsung/veles" rel="external nofollow noopener" target="_blank">Veles - Samsung Distributed machine learning platform</a></li> <li><a href="https://github.com/PrincetonVision/marvin" rel="external nofollow noopener" target="_blank">Marvin - A Minimalist GPU-only N-Dimensional ConvNets Framework</a></li> <li><a href="http://singa.incubator.apache.org/" rel="external nofollow noopener" target="_blank">Apache SINGA - A General Distributed Deep Learning Platform</a></li> <li><a href="https://github.com/amznlabs/amazon-dsstne" rel="external nofollow noopener" target="_blank">DSSTNE - Amazon’s library for building Deep Learning models</a></li> <li><a href="https://github.com/tensorflow/models/tree/master/syntaxnet" rel="external nofollow noopener" target="_blank">SyntaxNet - Google’s syntactic parser - A TensorFlow dependency library</a></li> <li><a href="http://mlpack.org/" rel="external nofollow noopener" target="_blank">mlpack - A scalable Machine Learning library</a></li> <li><a href="https://github.com/torchnet/torchnet" rel="external nofollow noopener" target="_blank">Torchnet - Torch based Deep Learning Library</a></li> <li><a href="https://github.com/baidu/paddle" rel="external nofollow noopener" target="_blank">Paddle - PArallel Distributed Deep LEarning by Baidu</a></li> <li><a href="http://neupy.com" rel="external nofollow noopener" target="_blank">NeuPy - Theano based Python library for ANN and Deep Learning</a></li> <li><a href="https://github.com/Lasagne/Lasagne" rel="external nofollow noopener" target="_blank">Lasagne - a lightweight library to build and train neural networks in Theano</a></li> <li><a href="https://github.com/dnouri/nolearn" rel="external nofollow noopener" target="_blank">nolearn - wrappers and abstractions around existing neural network libraries, most notably Lasagne</a></li> <li><a href="https://github.com/deepmind/sonnet" rel="external nofollow noopener" target="_blank">Sonnet - a library for constructing neural networks by Google’s DeepMind</a></li> <li><a href="https://github.com/pytorch/pytorch" rel="external nofollow noopener" target="_blank">PyTorch - Tensors and Dynamic neural networks in Python with strong GPU acceleration</a></li> <li><a href="https://github.com/Microsoft/CNTK" rel="external nofollow noopener" target="_blank">CNTK - Microsoft Cognitive Toolkit</a></li> <li><a href="https://github.com/SerpentAI/SerpentAI" rel="external nofollow noopener" target="_blank">Serpent.AI - Game agent framework: Use any video game as a deep learning sandbox</a></li> <li><a href="https://github.com/caffe2/caffe2" rel="external nofollow noopener" target="_blank">Caffe2 - A New Lightweight, Modular, and Scalable Deep Learning Framework</a></li> <li><a href="https://github.com/PAIR-code/deeplearnjs" rel="external nofollow noopener" target="_blank">deeplearn.js - Hardware-accelerated deep learning and linear algebra (NumPy) library for the web</a></li> </ol> <h3 id="miscellaneous">Miscellaneous</h3> <ol> <li><a href="https://plus.google.com/communities/112866381580457264725" rel="external nofollow noopener" target="_blank">Google Plus - Deep Learning Community</a></li> <li><a href="http://on-demand-gtc.gputechconf.com/gtcnew/on-demand-gtc.php?searchByKeyword=shelhamer&amp;searchItems=&amp;sessionTopic=&amp;sessionEvent=4&amp;sessionYear=2014&amp;sessionFormat=&amp;submit=&amp;select=+" rel="external nofollow noopener" target="_blank">Caffe Webinar</a></li> <li><a href="http://meta-guide.com/software-meta-guide/100-best-github-deep-learning/" rel="external nofollow noopener" target="_blank">100 Best Github Resources in Github for DL</a></li> <li><a href="https://code.google.com/p/word2vec/" rel="external nofollow noopener" target="_blank">Word2Vec</a></li> <li><a href="https://github.com/tleyden/docker/tree/master/caffe" rel="external nofollow noopener" target="_blank">Caffe DockerFile</a></li> <li><a href="https://github.com/TorontoDeepLearning/convnet" rel="external nofollow noopener" target="_blank">TorontoDeepLEarning convnet</a></li> <li><a href="https://github.com/clementfarabet/gfx.js" rel="external nofollow noopener" target="_blank">gfx.js</a></li> <li><a href="https://github.com/torch/torch7/wiki/Cheatsheet" rel="external nofollow noopener" target="_blank">Torch7 Cheat sheet</a></li> <li><a href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-864-advanced-natural-language-processing-fall-2005/" rel="external nofollow noopener" target="_blank">Misc from MIT’s ‘Advanced Natural Language Processing’ course</a></li> <li><a href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-867-machine-learning-fall-2006/lecture-notes/" rel="external nofollow noopener" target="_blank">Misc from MIT’s ‘Machine Learning’ course</a></li> <li><a href="http://ocw.mit.edu/courses/brain-and-cognitive-sciences/9-520-a-networks-for-learning-regression-and-classification-spring-2001/" rel="external nofollow noopener" target="_blank">Misc from MIT’s ‘Networks for Learning: Regression and Classification’ course</a></li> <li><a href="http://ocw.mit.edu/courses/health-sciences-and-technology/hst-723j-neural-coding-and-perception-of-sound-spring-2005/index.htm" rel="external nofollow noopener" target="_blank">Misc from MIT’s ‘Neural Coding and Perception of Sound’ course</a></li> <li><a href="http://www.datasciencecentral.com/profiles/blogs/implementing-a-distributed-deep-learning-network-over-spark" rel="external nofollow noopener" target="_blank">Implementing a Distributed Deep Learning Network over Spark</a></li> <li><a href="https://github.com/erikbern/deep-pink" rel="external nofollow noopener" target="_blank">A chess AI that learns to play chess using deep learning.</a></li> <li><a href="https://github.com/kristjankorjus/Replicating-DeepMind" rel="external nofollow noopener" target="_blank">Reproducing the results of “Playing Atari with Deep Reinforcement Learning” by DeepMind</a></li> <li><a href="https://github.com/idio/wiki2vec" rel="external nofollow noopener" target="_blank">Wiki2Vec. Getting Word2vec vectors for entities and word from Wikipedia Dumps</a></li> <li><a href="https://github.com/kuz/DeepMind-Atari-Deep-Q-Learner" rel="external nofollow noopener" target="_blank">The original code from the DeepMind article + tweaks</a></li> <li><a href="https://github.com/google/deepdream" rel="external nofollow noopener" target="_blank">Google deepdream - Neural Network art</a></li> <li><a href="https://gist.github.com/karpathy/587454dc0146a6ae21fc" rel="external nofollow noopener" target="_blank">An efficient, batched LSTM.</a></li> <li><a href="https://github.com/hexahedria/biaxial-rnn-music-composition" rel="external nofollow noopener" target="_blank">A recurrent neural network designed to generate classical music.</a></li> <li><a href="https://github.com/facebook/MemNN" rel="external nofollow noopener" target="_blank">Memory Networks Implementations - Facebook</a></li> <li><a href="https://github.com/cmusatyalab/openface" rel="external nofollow noopener" target="_blank">Face recognition with Google’s FaceNet deep neural network.</a></li> <li><a href="https://github.com/joeledenberg/DigitRecognition" rel="external nofollow noopener" target="_blank">Basic digit recognition neural network</a></li> <li><a href="https://www.projectoxford.ai/demo/emotion#detection" rel="external nofollow noopener" target="_blank">Emotion Recognition API Demo - Microsoft</a></li> <li><a href="https://github.com/ethereon/caffe-tensorflow" rel="external nofollow noopener" target="_blank">Proof of concept for loading Caffe models in TensorFlow</a></li> <li><a href="http://pjreddie.com/darknet/yolo/#webcam" rel="external nofollow noopener" target="_blank">YOLO: Real-Time Object Detection</a></li> <li><a href="https://github.com/Rochester-NRT/AlphaGo" rel="external nofollow noopener" target="_blank">AlphaGo - A replication of DeepMind’s 2016 Nature publication, “Mastering the game of Go with deep neural networks and tree search”</a></li> <li><a href="https://github.com/ZuzooVn/machine-learning-for-software-engineers" rel="external nofollow noopener" target="_blank">Machine Learning for Software Engineers</a></li> <li><a href="https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471#.oa4rzez3g" rel="external nofollow noopener" target="_blank">Machine Learning is Fun!</a></li> <li><a href="https://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A" rel="external nofollow noopener" target="_blank">Siraj Raval’s Deep Learning tutorials</a></li> <li> <a href="https://github.com/natanielruiz/dockerface" rel="external nofollow noopener" target="_blank">Dockerface</a> - Easy to install and use deep learning Faster R-CNN face detection for images and video in a docker container.</li> <li> <a href="https://github.com/ybayle/awesome-deep-learning-music" rel="external nofollow noopener" target="_blank">Awesome Deep Learning Music</a> - Curated list of articles related to deep learning scientific research applied to music</li> </ol> <hr> <h3 id="license">License</h3> <p><a href="http://creativecommons.org/publicdomain/zero/1.0/" rel="external nofollow noopener" target="_blank"><img src="http://i.creativecommons.org/p/zero/1.0/88x31.png" alt="CC0"></a></p> <p>To the extent possible under law, <a href="https://linkedin.com/in/Christofidis" rel="external nofollow noopener" target="_blank">Christos Christofidis</a> has waived all copyright and related or neighboring rights to this work.</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Piyush Tiwary. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-DP8LD8Z4LH"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-DP8LD8Z4LH");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>